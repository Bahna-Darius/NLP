{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-14T14:54:02.320670Z",
     "start_time": "2024-08-14T14:54:02.261439Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "import pandas as pd\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "set_seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T13:33:53.205079Z",
     "start_time": "2024-08-14T13:33:53.107068Z"
    }
   },
   "id": "bbe07596a3668f4",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Darius\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9debc075333a4e37927f3ef787c807ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5af0d00c2870405f8cfeef03bda1955d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8994604d12e44c1384616f9623cc094b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darius\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "      label    score\n0  POSITIVE  0.99988",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>POSITIVE</td>\n      <td>0.99988</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifer = pipeline(task=\"text-classification\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "text = \"I am happy\"\n",
    "output = classifer(text)\n",
    "pd.DataFrame(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T10:32:19.936331Z",
     "start_time": "2024-08-14T10:32:05.882537Z"
    }
   },
   "id": "55ba1645c2679f06",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "66d05d107a4fad38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "## Token Classification Model\n",
    "\n",
    "Token is a word or a character. In NER, we are interested in identifying the tokens that are entities.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9bd0379a93f4db8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-large-finetuned-conll03-english were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\Darius\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "  entity     score  index      word  start  end\n0  I-PER  0.999936      4     ▁Dari     11   15\n1  I-PER  0.999952      5        us     15   17\n2  I-ORG  0.999990     10       ▁Bi     30   32\n3  I-ORG  0.999985     11        xa     32   34\n4  I-ORG  0.999990     12         g     34   35\n5  I-ORG  0.999988     13  ▁Romania     36   43",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entity</th>\n      <th>score</th>\n      <th>index</th>\n      <th>word</th>\n      <th>start</th>\n      <th>end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I-PER</td>\n      <td>0.999936</td>\n      <td>4</td>\n      <td>▁Dari</td>\n      <td>11</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I-PER</td>\n      <td>0.999952</td>\n      <td>5</td>\n      <td>us</td>\n      <td>15</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I-ORG</td>\n      <td>0.999990</td>\n      <td>10</td>\n      <td>▁Bi</td>\n      <td>30</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I-ORG</td>\n      <td>0.999985</td>\n      <td>11</td>\n      <td>xa</td>\n      <td>32</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I-ORG</td>\n      <td>0.999990</td>\n      <td>12</td>\n      <td>g</td>\n      <td>34</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>I-ORG</td>\n      <td>0.999988</td>\n      <td>13</td>\n      <td>▁Romania</td>\n      <td>36</td>\n      <td>43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_taegger = pipeline(task=\"ner\", model=\"FacebookAI/xlm-roberta-large-finetuned-conll03-english\")   # ner is an alias for token-classification\n",
    "text_token = \"My name is Darius. I work for Bixag Romania.\"\n",
    "\n",
    "output_token = ner_taegger(text_token)\n",
    "pd.DataFrame(output_token)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T11:06:04.284509Z",
     "start_time": "2024-08-14T11:06:01.367307Z"
    }
   },
   "id": "12f1046e397d8e61",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "46d5aacebef8ae0e"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ed906819964ff3ed"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2e2a3845e857966d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question Answering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f76dfb851d37375"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Dear Amazon, last week I ordered an Optimus Prime action figure from your\n",
    "online store in India. Unfortunately when I opened the package, I discovered to\n",
    "my horror that I had been sent an action figure of Megatron instead!\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T11:35:59.979356Z",
     "start_time": "2024-08-14T11:35:59.974569Z"
    }
   },
   "id": "7383c2f0220d6356",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\Darius\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reader = pipeline(task=\"question-answering\")\n",
    "\n",
    "question_customer = \"What was wrong?\"\n",
    "question_customer_1 = \"What did you order?\"\n",
    "question_customer_2 = \"What did you receive?\"\n",
    "\n",
    "\n",
    "output_question = reader(question=question_customer, context=text)      # use default model, but we can change with use models="
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T11:40:34.977551Z",
     "start_time": "2024-08-14T11:40:34.341782Z"
    }
   },
   "id": "2d097ca195a64af9",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "score                                               0.27679\nstart                                                   170\nend                                                     222\nanswer    I had been sent an action figure of Megatron i...\ndtype: object"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(output_question)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T11:40:45.113787Z",
     "start_time": "2024-08-14T11:40:45.107439Z"
    }
   },
   "id": "4a17feaf386b389d",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e87f83d0199a0f58"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3a52544d32c97d79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summarization Pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e85443ad4d9384d6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2363c7e4cf444a21b0a89e7b545d2502"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e414531d53c4f69a92273c41502b731"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "259942f0717e4b8b84e89bbc0103016d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "337034def8ad48e7a663edb02e11613a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73af4f2a1cef41b6b9a790e02a8145e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darius\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Your max_length is set to 142, but your input_length is only 51. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n"
     ]
    }
   ],
   "source": [
    "summary = pipeline(task=\"summarization\")\n",
    "\n",
    "output_summary = summary(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T11:49:40.084483Z",
     "start_time": "2024-08-14T11:48:56.889744Z"
    }
   },
   "id": "17d840f1478f4c25",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'summary_text': ' Amazon sent an Optimus Prime action figure from your online store in India . Unfortunately when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! Amazon.com has been sending a figure of Optimus Prime instead of Optimus Optimus Prime .'}]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_summary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T11:49:50.269012Z",
     "start_time": "2024-08-14T11:49:50.264757Z"
    }
   },
   "id": "ba1ea6d776bee258",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'sending a figure of Optimus Prime instead of Optimus Optimus Prime .'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_summary[0][\"summary_text\"][len(text):]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T11:54:03.534867Z",
     "start_time": "2024-08-14T11:54:03.528598Z"
    }
   },
   "id": "dba446ae656902bc",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a295de4de48d212d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e51facc4cfc7be30"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "213ac44c515ea052"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Text Generation Pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f32846b6d1f9907"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nDear Amazon, last week I ordered an Optimus Prime action figure from your\\nonline store in India. Unfortunately when I opened the package, I discovered to\\nmy horror that I had been sent an action figure of Megatron instead!\\n'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T13:36:06.980538Z",
     "start_time": "2024-08-14T13:36:06.975496Z"
    }
   },
   "id": "e41b061bf4f2e310",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(task=\"text-generation\")\n",
    "\n",
    "response = \"I am sorry to hear that your order wax mixed up\"\n",
    "prompt = f'User: {text} + f\"Customer Service Response: {response}'\n",
    "\n",
    "output_generator = generator(prompt, max_length=128)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T13:40:26.376382Z",
     "start_time": "2024-08-14T13:40:21.865768Z"
    }
   },
   "id": "fef92f53bc3ec8a5",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'generated_text': \"User: \\nDear Amazon, last week I ordered an Optimus Prime action figure from your\\nonline store in India. Unfortunately when I opened the package, I discovered to\\nmy horror that I had been sent an action figure of Megatron instead!\\n\\nCustomer Service Response: I am sorry to hear that your order wax mixed up or that you were not ordered exactly as described. The\\n\\naction figure arrived in a beautiful box inside a\\n\\nbox that I'm hoping will hold up great condition, especially when it comes in a\\n\\ndeluxe box. But I can make it look bad on you or have something to do\"}]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_generator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T13:43:01.537234Z",
     "start_time": "2024-08-14T13:43:01.532058Z"
    }
   },
   "id": "5b5dedb89fd09320",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e161088959e57d12"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6267827d2a860384"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "62198d7b19abbd89"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Translation Text Pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f20dec87fd6492b3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision 686f1db (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f21a79a3ac8469f80b849c30456991e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f42b95ca52374f489dd39300defc4423"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb77960c0984421e985a3161cb4373cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5535588b1bb54fdfb49701b877d77894"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc2895e1b61e4549961111c291d13002"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darius\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(task=\"translation_en_to_ro\")\n",
    "\n",
    "output_translator = translator(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T13:57:36.646831Z",
     "start_time": "2024-08-14T13:57:00.009872Z"
    }
   },
   "id": "d04b6f07f3eac872",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'translation_text': 'Stimate Amazon, săptămâna trecută am comandat o figură de acţiune Optimus Prime de la magazinul dvs. online din India şi, din păcate, când am deschis pachetul, am aflat cu groază că mi s-a trimis în schimb o figură de acţiune a Megatron!'}]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_translator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T13:57:41.085920Z",
     "start_time": "2024-08-14T13:57:41.081345Z"
    }
   },
   "id": "8618f199ebc45bf5",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ca0dc9e44541c5d7"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e0a5719bf85ef9a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Text to Speech Pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd45f73edd74f960"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nDear Amazon, last week I ordered an Optimus Prime action figure from your\\nonline store in India. Unfortunately when I opened the package, I discovered to\\nmy horror that I had been sent an action figure of Megatron instead!\\n'"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T15:11:08.360568Z",
     "start_time": "2024-08-14T15:11:08.355566Z"
    }
   },
   "id": "398cbec59f4bde2e",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to suno/bark-small and revision 645cfba (https://huggingface.co/suno/bark-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/8.80k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67a7ec4fa9124a7d9078cc80bc61d599"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/1.68G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0eb1302ec1744bf29eaee65a86873335"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darius\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "C:\\Users\\Darius\\PycharmProjects\\NLP\\venv\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/4.91k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c594f12b88d2489fa7c1ef117c71fc5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/353 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d238560d58f54e2698b68bfbeea141d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc4f84e362f944e6a5220a0357ec7e16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/2.92M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e76de96320504b90b8c89092ac2bb725"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8de61c0462fe4b2c9ff311046e6488e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "synth = pipeline(task=\"text-to-speech\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T14:58:04.177865Z",
     "start_time": "2024-08-14T14:57:12.565294Z"
    }
   },
   "id": "bbcd74931a6fa571",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "speech = synth(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T15:04:26.713510Z",
     "start_time": "2024-08-14T14:58:56.983225Z"
    }
   },
   "id": "a9693b478b69fbfa",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sf.write(\"speech.wav\", speech[\"audio\"].T, samplerate=speech[\"sampling_rate\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T15:09:06.152339Z",
     "start_time": "2024-08-14T15:09:06.141218Z"
    }
   },
   "id": "6b77c777438032ef",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8b8645164f86a1cb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9fa3c371385b735b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
